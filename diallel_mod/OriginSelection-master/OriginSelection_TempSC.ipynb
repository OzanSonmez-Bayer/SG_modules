{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Diallel Table for Origin Selection Step by Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  data = yaml.load(f.read()) or {}\n",
      "/usr/local/anaconda/lib/python3.7/site-packages/distributed/config.py:20: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  defaults = yaml.load(f)\n",
      "/usr/local/anaconda/lib/python3.7/site-packages/dask/dataframe/utils.py:13: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import s3fs\n",
    "import MidParentValue as MP\n",
    "import rulefilter as rf\n",
    "import utils\n",
    "import master_table as mt\n",
    "import collections\n",
    "import re\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import dask\n",
    "from dask import delayed\n",
    "import dask.dataframe as dd\n",
    "from functools import reduce\n",
    "import itertools\n",
    "import time\n",
    "import json\n",
    "import hvac\n",
    "import boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## Import GCA master file \n",
    "\n",
    "if 'ec2' in os.environ['HOME']:\n",
    "    master_file = utils.read_as_dask_1('ycao1/OriginSelection/master_wide_test.csv', bucket='veg-apd-sdi-predictiveanalytcs-prod-workspace')\n",
    "else:\n",
    "    master_file = utils.read_as_dask('ycao1/OriginSelection/master_wide_test.csv', bucket='veg-apd-sdi-predictiveanalytcs-prod-workspace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_file = master_file.compute().set_index(pd.Index(range(master_file.compute().shape[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## Import Key Inbred Lines \n",
    "\n",
    "key_inbred = pd.read_csv('/mnt/TempSC/2020_key_inbred_lines_tempSC.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## Filter by Key Inbred\n",
    "\n",
    "master_file_filtered = master_file[master_file['PEDIGREE_NAME'].isin(key_inbred['Pedigree'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## Filter by Heterotic Group\n",
    "\n",
    "master_file_filtered = rf.filter_by_HETGP(master_file_filtered, het=['678', '83', '89', 'A', 'SLM804'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Master Shape Proc:  (107, 144)\n",
      "Master Shape fresh: (140, 144)\n"
     ]
    }
   ],
   "source": [
    "########### Split the filtered master file by INBRED_MKT_TYPE, TEMP PROC and TEMP FRESH\n",
    "\n",
    "master_file_proc = master_file_filtered[master_file_filtered['INBRED_MKT_TYPE_GCV'] == 'TEMP PROC']\n",
    "print(f'{\"Master Shape Proc:\":20}{master_file_proc.shape}')\n",
    "\n",
    "master_file_fresh = master_file_filtered[master_file_filtered['INBRED_MKT_TYPE_GCV'] == 'TEMP FRESH']\n",
    "print(f'{\"Master Shape fresh:\":20}{master_file_fresh.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "########### Getting Trait list \n",
    "# master_file_filtered = master_file\n",
    "# traits = [col for col in master_file_filtered.columns if '_predicted.value' in col]\n",
    "traits = [col for col in master_file_filtered.columns if 'predicted.value_' in col]\n",
    "traits_1 = []\n",
    "for tt in traits: \n",
    "    t_1 = re.sub('predicted.value_', '', tt)\n",
    "#     if (t_1 != 'SC_RWCT') & (t_1 != 'FBRIX'):\n",
    "    traits_1.append(t_1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(249, 144)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_file_filtered.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for whole data: 0.29 seconds\n"
     ]
    }
   ],
   "source": [
    "start_1 = time.time()\n",
    "test = MP.gather_mid_value(dd.from_pandas(master_file_filtered, npartitions=3), traits_1)\n",
    "print(f'Time for whole data: {time.time()-start_1:.2f} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############# Calculate mid parent value by inbred market type\n",
    "\n",
    "# Process \n",
    "start_1 = time.time()\n",
    "# diallel_table_1 = MP.gather_mid_value(master_file_filtered, traits_1)\n",
    "diallel_table_proc = MP.gather_mid_value(dd.from_pandas(master_file_proc, npartitions=3), traits_1)\n",
    "print(f'Time for Proc: {time.time()-start_1:.2f} seconds')\n",
    "\n",
    "# Fresh\n",
    "start_2 = time.time()\n",
    "# diallel_table_1 = MP.gather_mid_value(master_file_filtered, traits_1)\n",
    "diallel_table_fresh = MP.gather_mid_value(dd.from_pandas(master_file_fresh, npartitions=3), traits_1)\n",
    "print(f'Time for Fresh: {time.time()-start_2:.2f} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############### Get reference data in one table\n",
    "\n",
    "reference_cols = [col for col in master_file_filtered.columns if not any(tr in col for tr in traits_1)]\n",
    "reference_table = master_file_filtered[reference_cols]\n",
    "reference_table = reference_table.drop(columns=['PEDIGREE'], axis=1)\n",
    "reference_table = reference_table.drop_duplicates(subset='PEDIGREE_NAME', keep='last') # there are duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############### Add reference table to diallel table\n",
    "\n",
    "# Add reference table to diallel table\n",
    "start = time.time()\n",
    "print(f'{\"Master Shape BEFORE adding reference data:\":20}{diallel_table_proc.shape}')\n",
    "diallel_table_proc = utils.add_reference_dat(diallel_table_proc, reference_table)\n",
    "print(f'{\"Master Shape AFTER adding reference data:\":20}{diallel_table_proc.shape}')\n",
    "diallel_table_fresh = utils.add_reference_dat(diallel_table_fresh, reference_table)\n",
    "end = time.time()\n",
    "print(f'Time for Proc: {end-start:.2f} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############### Add clean origin to the table\n",
    "diallel_table_proc['clean_origin'] = diallel_table_proc['P1_M.GERMPLASM.ORIGIN'] + '__' + diallel_table_proc['P2_M.GERMPLASM.ORIGIN']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Origin Selection: Create New DevX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############## Filter new dev crosses by het and inbred stage combos\n",
    "\n",
    "# Proc\n",
    "het_comb_proc = ['A_A', '678_678', '83_678','678_83']\n",
    "inbred_stage_comb_proc = ['PS2_PS2', 'PS2_PS3','PS3_PS3', 'PS2_CM', 'PS3_CM','CM_CM', 'CM_P1', 'CM_P2', 'CM_P3',\n",
    "                         'PS3_PS2', 'CM_PS2', 'CM_PS3', 'P1_CM', 'P2_CM', 'CM_P3']\n",
    "\n",
    "diallel_table_proc_filtered = rf.filter_on_het_combination(diallel_table_proc, het_comb_proc)\n",
    "diallel_table_proc_filtered = rf.filter_on_inbrdstg(diallel_table_proc_filtered, inbred_stage_comb_proc)\n",
    "\n",
    "# Fresh\n",
    "het_comb_fresh = ['A_A', '678_678', 'SLM804_SLM804', '678_SLM804', '89_SL804', '83_678', 'SLM804_678', 'SL804_89', '678_83']\n",
    "inbred_stage_comb_fresh = ['PS2_PS2', 'PS2_PS3', 'PS3_PS3', 'PS2_CM', 'PS3_CM','CM_CM', 'CM_P1', 'CM_P2', 'CM_P3',\n",
    "                          'PS3_PS2', 'CM_PS2', 'CM_PS3', 'P1_CM', 'P2_CM', 'CM_P3']\n",
    "\n",
    "diallel_table_fresh_filtered = rf.filter_on_het_combination(diallel_table_fresh, het_comb_fresh)\n",
    "diallel_table_fresh_filtered = rf.filter_on_inbrdstg(diallel_table_fresh_filtered, inbred_stage_comb_fresh)\n",
    "\n",
    "\n",
    "####################### Eliminate ORIGIN = ORIGIN\n",
    "diallel_table_proc_filtered = rf.remove_same_origin(diallel_table_proc_filtered)\n",
    "diallel_table_fresh_filtered = rf.remove_same_origin(diallel_table_fresh_filtered)\n",
    "\n",
    "\n",
    "####################### Write results to a csv file\n",
    "\n",
    "diallel_table_proc_filtered.to_csv('/mnt/TempSC/temp_sc_proc_diallel.csv')\n",
    "diallel_table_fresh_filtered.to_csv('/mnt/TempSC/temp_sc_fresh_diallel.csv')\n",
    "\n",
    "###################### Upload file to S3\n",
    "\n",
    "import logging\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "utils.upload_file(file_name = \"/mnt/TempSC/temp_sc_fresh_diallel.csv\", bucket=\"veg-apd-sdi-predictiveanalytcs-prod-workspace\",\n",
    "            object_name = 'ycao1/OriginSelection/Corn/DiallelTable/+OriginSelection/Temp_fresh_diallel.csv')\n",
    "utils.upload_file(file_name = \"/mnt/TempSC//temp_sc_proc_diallel.csv\", bucket=\"veg-apd-sdi-predictiveanalytcs-prod-workspace\",\n",
    "            object_name = 'ycao1/OriginSelection/Corn/DiallelTable/+OriginSelection/Temp_proc_diallel.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
